{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a01178-5862-4415-81c1-9784fb9e3cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>v1_mean</th>\n",
       "      <th>v2_mean</th>\n",
       "      <th>a_mean</th>\n",
       "      <th>ndt_mean</th>\n",
       "      <th>alpha_mean</th>\n",
       "      <th>accuracy_percentage</th>\n",
       "      <th>mean_log_rt</th>\n",
       "      <th>RT_mean_correct_error</th>\n",
       "      <th>mean_correct</th>\n",
       "      <th>...</th>\n",
       "      <th>error_array</th>\n",
       "      <th>RT_Cor_arr</th>\n",
       "      <th>q1_C</th>\n",
       "      <th>q2_C</th>\n",
       "      <th>q3_C</th>\n",
       "      <th>q4_C</th>\n",
       "      <th>q1_E</th>\n",
       "      <th>q2_E</th>\n",
       "      <th>q3_E</th>\n",
       "      <th>q4_E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3024_class_words_part_1.dat</td>\n",
       "      <td>2.613922</td>\n",
       "      <td>-1.825480</td>\n",
       "      <td>1.238268</td>\n",
       "      <td>0.488421</td>\n",
       "      <td>1.822207</td>\n",
       "      <td>0.944862</td>\n",
       "      <td>6.604221</td>\n",
       "      <td>0.761732</td>\n",
       "      <td>0.759056</td>\n",
       "      <td>...</td>\n",
       "      <td>51     0.834\\n61     0.611\\n69     0.657\\n71  ...</td>\n",
       "      <td>0      1.346\\n1      0.698\\n2      0.930\\n3   ...</td>\n",
       "      <td>[0.611 0.619 0.56  0.601 0.53  0.617 0.571 0.4...</td>\n",
       "      <td>[0.698 0.658 0.634 0.635 0.642 0.682 0.683 0.6...</td>\n",
       "      <td>[0.802 0.771 0.722 0.794 0.754 0.779 0.795 0.7...</td>\n",
       "      <td>[1.346 0.93  1.234 0.858 0.859 0.866 0.858 0.9...</td>\n",
       "      <td>[0.611 0.657 0.585 0.57  0.643 0.571]</td>\n",
       "      <td>[0.698 0.667 0.738 0.738 0.706 0.698]</td>\n",
       "      <td>[0.834 0.891 0.834 0.881]</td>\n",
       "      <td>[0.922 0.986 1.091 1.067 1.146 1.233]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1025_class_words_part_2.dat</td>\n",
       "      <td>3.969212</td>\n",
       "      <td>-3.339207</td>\n",
       "      <td>0.993811</td>\n",
       "      <td>0.450063</td>\n",
       "      <td>1.853775</td>\n",
       "      <td>0.977500</td>\n",
       "      <td>6.359827</td>\n",
       "      <td>0.589127</td>\n",
       "      <td>0.587941</td>\n",
       "      <td>...</td>\n",
       "      <td>49     0.681\\n65     0.552\\n116    0.593\\n218 ...</td>\n",
       "      <td>0      0.665\\n1      0.529\\n2      0.520\\n3   ...</td>\n",
       "      <td>[0.52  0.506 0.513 0.52  0.481 0.521 0.497 0.4...</td>\n",
       "      <td>[0.529 0.553 0.546 0.546 0.538 0.545 0.53  0.5...</td>\n",
       "      <td>[0.594 0.569 0.585 0.569 0.562 0.577 0.592 0.5...</td>\n",
       "      <td>[0.665 0.706 0.617 0.664 0.961 0.625 0.673 0.7...</td>\n",
       "      <td>[0.552 0.546 0.498]</td>\n",
       "      <td>[0.593 0.574]</td>\n",
       "      <td>[0.681 0.616]</td>\n",
       "      <td>[0.994 0.712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1011_class_pictures_part_1.dat</td>\n",
       "      <td>0.840939</td>\n",
       "      <td>-1.702453</td>\n",
       "      <td>0.815696</td>\n",
       "      <td>0.613419</td>\n",
       "      <td>1.434516</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>6.750704</td>\n",
       "      <td>0.871310</td>\n",
       "      <td>0.869624</td>\n",
       "      <td>...</td>\n",
       "      <td>4      1.210\\n6      1.014\\n22     0.736\\n34  ...</td>\n",
       "      <td>1      0.867\\n2      0.941\\n3      0.725\\n5   ...</td>\n",
       "      <td>[0.725 0.719 0.639 0.703 0.729 0.744 0.697 0.6...</td>\n",
       "      <td>[0.806 0.832 0.83  0.768 0.765 0.81  0.759 0.7...</td>\n",
       "      <td>[0.867 0.941 0.947 0.922 0.941 0.872 0.903 0.9...</td>\n",
       "      <td>[0.953 0.961 1.081 1.034 1.184 1.641 1.034 1.1...</td>\n",
       "      <td>[0.736 0.735 0.705 0.721 0.677 0.61  0.715 0.6...</td>\n",
       "      <td>[0.745 0.761 0.827 0.744 0.83  0.788 0.81  0.8...</td>\n",
       "      <td>[0.982 0.947 0.968 0.879 0.922 0.912 0.888 0.969]</td>\n",
       "      <td>[1.21  1.014 1.002 1.035 1.204 1.024 0.989 1.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>017_class_pictures_part_1.dat</td>\n",
       "      <td>2.510240</td>\n",
       "      <td>-3.773617</td>\n",
       "      <td>1.557438</td>\n",
       "      <td>0.555524</td>\n",
       "      <td>1.775415</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>6.681648</td>\n",
       "      <td>0.819220</td>\n",
       "      <td>0.814469</td>\n",
       "      <td>...</td>\n",
       "      <td>104    1.172\\n111    0.923\\n118    1.108\\n129 ...</td>\n",
       "      <td>1      0.721\\n2      0.693\\n3      0.724\\n4   ...</td>\n",
       "      <td>[0.693 0.686 0.67  0.608 0.693 0.666 0.697 0.6...</td>\n",
       "      <td>[0.721 0.724 0.753 0.757 0.709 0.731 0.71  0.7...</td>\n",
       "      <td>[0.86  0.793 0.783 0.777 0.8   0.861 0.815 0.8...</td>\n",
       "      <td>[0.899 0.973 1.165 1.03  1.141 0.92  0.878 0.9...</td>\n",
       "      <td>[0.923]</td>\n",
       "      <td>[1.005]</td>\n",
       "      <td>[1.108]</td>\n",
       "      <td>[1.172]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004_class_pictures_part_1.dat</td>\n",
       "      <td>1.648697</td>\n",
       "      <td>-1.858000</td>\n",
       "      <td>1.328944</td>\n",
       "      <td>0.594462</td>\n",
       "      <td>1.908944</td>\n",
       "      <td>0.924623</td>\n",
       "      <td>6.787777</td>\n",
       "      <td>0.948915</td>\n",
       "      <td>0.911571</td>\n",
       "      <td>...</td>\n",
       "      <td>42     0.818\\n45     0.918\\n55     1.239\\n62  ...</td>\n",
       "      <td>1      0.852\\n2      0.763\\n3      0.631\\n4   ...</td>\n",
       "      <td>[0.631 0.75  0.747 0.721 0.749 0.679 0.678 0.7...</td>\n",
       "      <td>[0.852 0.763 0.777 0.801 0.795 0.789 0.758 0.7...</td>\n",
       "      <td>[0.886 0.927 0.919 0.949 0.892 0.894 0.888 0.9...</td>\n",
       "      <td>[1.892 1.057 1.335 0.984 1.054 1.038 1.044 1.0...</td>\n",
       "      <td>[0.818 0.918 0.791 0.92 ]</td>\n",
       "      <td>[1.239 1.09  1.118 1.224]</td>\n",
       "      <td>[1.279 1.295 1.584]</td>\n",
       "      <td>[2.391 1.77  2.223 2.445]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Experiment   v1_mean   v2_mean    a_mean  ndt_mean  \\\n",
       "0     3024_class_words_part_1.dat  2.613922 -1.825480  1.238268  0.488421   \n",
       "1     1025_class_words_part_2.dat  3.969212 -3.339207  0.993811  0.450063   \n",
       "2  1011_class_pictures_part_1.dat  0.840939 -1.702453  0.815696  0.613419   \n",
       "3   017_class_pictures_part_1.dat  2.510240 -3.773617  1.557438  0.555524   \n",
       "4  1004_class_pictures_part_1.dat  1.648697 -1.858000  1.328944  0.594462   \n",
       "\n",
       "   alpha_mean  accuracy_percentage  mean_log_rt  RT_mean_correct_error  \\\n",
       "0    1.822207             0.944862     6.604221               0.761732   \n",
       "1    1.853775             0.977500     6.359827               0.589127   \n",
       "2    1.434516             0.825000     6.750704               0.871310   \n",
       "3    1.775415             0.980000     6.681648               0.819220   \n",
       "4    1.908944             0.924623     6.787777               0.948915   \n",
       "\n",
       "   mean_correct  ...                                        error_array  \\\n",
       "0      0.759056  ...  51     0.834\\n61     0.611\\n69     0.657\\n71  ...   \n",
       "1      0.587941  ...  49     0.681\\n65     0.552\\n116    0.593\\n218 ...   \n",
       "2      0.869624  ...  4      1.210\\n6      1.014\\n22     0.736\\n34  ...   \n",
       "3      0.814469  ...  104    1.172\\n111    0.923\\n118    1.108\\n129 ...   \n",
       "4      0.911571  ...  42     0.818\\n45     0.918\\n55     1.239\\n62  ...   \n",
       "\n",
       "                                          RT_Cor_arr  \\\n",
       "0  0      1.346\\n1      0.698\\n2      0.930\\n3   ...   \n",
       "1  0      0.665\\n1      0.529\\n2      0.520\\n3   ...   \n",
       "2  1      0.867\\n2      0.941\\n3      0.725\\n5   ...   \n",
       "3  1      0.721\\n2      0.693\\n3      0.724\\n4   ...   \n",
       "4  1      0.852\\n2      0.763\\n3      0.631\\n4   ...   \n",
       "\n",
       "                                                q1_C  \\\n",
       "0  [0.611 0.619 0.56  0.601 0.53  0.617 0.571 0.4...   \n",
       "1  [0.52  0.506 0.513 0.52  0.481 0.521 0.497 0.4...   \n",
       "2  [0.725 0.719 0.639 0.703 0.729 0.744 0.697 0.6...   \n",
       "3  [0.693 0.686 0.67  0.608 0.693 0.666 0.697 0.6...   \n",
       "4  [0.631 0.75  0.747 0.721 0.749 0.679 0.678 0.7...   \n",
       "\n",
       "                                                q2_C  \\\n",
       "0  [0.698 0.658 0.634 0.635 0.642 0.682 0.683 0.6...   \n",
       "1  [0.529 0.553 0.546 0.546 0.538 0.545 0.53  0.5...   \n",
       "2  [0.806 0.832 0.83  0.768 0.765 0.81  0.759 0.7...   \n",
       "3  [0.721 0.724 0.753 0.757 0.709 0.731 0.71  0.7...   \n",
       "4  [0.852 0.763 0.777 0.801 0.795 0.789 0.758 0.7...   \n",
       "\n",
       "                                                q3_C  \\\n",
       "0  [0.802 0.771 0.722 0.794 0.754 0.779 0.795 0.7...   \n",
       "1  [0.594 0.569 0.585 0.569 0.562 0.577 0.592 0.5...   \n",
       "2  [0.867 0.941 0.947 0.922 0.941 0.872 0.903 0.9...   \n",
       "3  [0.86  0.793 0.783 0.777 0.8   0.861 0.815 0.8...   \n",
       "4  [0.886 0.927 0.919 0.949 0.892 0.894 0.888 0.9...   \n",
       "\n",
       "                                                q4_C  \\\n",
       "0  [1.346 0.93  1.234 0.858 0.859 0.866 0.858 0.9...   \n",
       "1  [0.665 0.706 0.617 0.664 0.961 0.625 0.673 0.7...   \n",
       "2  [0.953 0.961 1.081 1.034 1.184 1.641 1.034 1.1...   \n",
       "3  [0.899 0.973 1.165 1.03  1.141 0.92  0.878 0.9...   \n",
       "4  [1.892 1.057 1.335 0.984 1.054 1.038 1.044 1.0...   \n",
       "\n",
       "                                                q1_E  \\\n",
       "0              [0.611 0.657 0.585 0.57  0.643 0.571]   \n",
       "1                                [0.552 0.546 0.498]   \n",
       "2  [0.736 0.735 0.705 0.721 0.677 0.61  0.715 0.6...   \n",
       "3                                            [0.923]   \n",
       "4                          [0.818 0.918 0.791 0.92 ]   \n",
       "\n",
       "                                                q2_E  \\\n",
       "0              [0.698 0.667 0.738 0.738 0.706 0.698]   \n",
       "1                                      [0.593 0.574]   \n",
       "2  [0.745 0.761 0.827 0.744 0.83  0.788 0.81  0.8...   \n",
       "3                                            [1.005]   \n",
       "4                          [1.239 1.09  1.118 1.224]   \n",
       "\n",
       "                                                q3_E  \\\n",
       "0                          [0.834 0.891 0.834 0.881]   \n",
       "1                                      [0.681 0.616]   \n",
       "2  [0.982 0.947 0.968 0.879 0.922 0.912 0.888 0.969]   \n",
       "3                                            [1.108]   \n",
       "4                                [1.279 1.295 1.584]   \n",
       "\n",
       "                                                q4_E  \n",
       "0              [0.922 0.986 1.091 1.067 1.146 1.233]  \n",
       "1                                      [0.994 0.712]  \n",
       "2  [1.21  1.014 1.002 1.035 1.204 1.024 0.989 1.3...  \n",
       "3                                            [1.172]  \n",
       "4                          [2.391 1.77  2.223 2.445]  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'EZ_study1_params_plus_rt(log&main)_acc_correcte.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe for a preview\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c20e203-189e-4b21-862b-1a2c7a26b8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lexical_decision_part1.csv',\n",
       " 'lexical_decision_part2.csv',\n",
       " 'recognition_memory_part1.csv',\n",
       " 'recognition_memory_part2.csv')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering the data based on task and session part\n",
    "lexical_decision_part1 = data[data['Experiment'].str.contains('class_words_part_1')]\n",
    "lexical_decision_part2 = data[data['Experiment'].str.contains('class_words_part_2')]\n",
    "recognition_memory_part1 = data[data['Experiment'].str.contains('class_pictures_part_1')]\n",
    "recognition_memory_part2 = data[data['Experiment'].str.contains('class_pictures_part_2')]\n",
    "\n",
    "# File paths for the new CSV files\n",
    "file_ld_part1 = 'lexical_decision_part1.csv'\n",
    "file_ld_part2 = 'lexical_decision_part2.csv'\n",
    "file_rm_part1 = 'recognition_memory_part1.csv'\n",
    "file_rm_part2 = 'recognition_memory_part2.csv'\n",
    "\n",
    "# Saving the dataframes to CSV files\n",
    "lexical_decision_part1.to_csv(file_ld_part1, index=False)\n",
    "lexical_decision_part2.to_csv(file_ld_part2, index=False)\n",
    "recognition_memory_part1.to_csv(file_rm_part1, index=False)\n",
    "recognition_memory_part2.to_csv(file_rm_part2, index=False)\n",
    "\n",
    "file_ld_part1, file_ld_part2, file_rm_part1, file_rm_part2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982ce830-810a-43d0-9770-b6b353b3dc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_290979/1179958329.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['participant_ID'] = df['Experiment'].str.extract(r'(\\d+)')\n",
      "/tmp/ipykernel_290979/1179958329.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['participant_ID'] = pd.to_numeric(df['participant_ID'])\n",
      "/tmp/ipykernel_290979/1179958329.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['participant_ID'] = df['Experiment'].str.extract(r'(\\d+)')\n",
      "/tmp/ipykernel_290979/1179958329.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['participant_ID'] = pd.to_numeric(df['participant_ID'])\n",
      "/tmp/ipykernel_290979/1179958329.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['participant_ID'] = df['Experiment'].str.extract(r'(\\d+)')\n",
      "/tmp/ipykernel_290979/1179958329.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['participant_ID'] = pd.to_numeric(df['participant_ID'])\n",
      "/tmp/ipykernel_290979/1179958329.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['participant_ID'] = df['Experiment'].str.extract(r'(\\d+)')\n",
      "/tmp/ipykernel_290979/1179958329.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['participant_ID'] = pd.to_numeric(df['participant_ID'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('lexical_decision_part1_sorted.csv',\n",
       " 'lexical_decision_part2_sorted.csv',\n",
       " 'recognition_memory_part1_sorted.csv',\n",
       " 'recognition_memory_part2_sorted.csv')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract ID and sort the dataframe\n",
    "def process_dataframe(df):\n",
    "    # Extracting participant's ID from the 'Experiment' column\n",
    "    df['participant_ID'] = df['Experiment'].str.extract(r'(\\d+)')\n",
    "    # Converting ID to integer for proper sorting\n",
    "    df['participant_ID'] = pd.to_numeric(df['participant_ID'])\n",
    "    # Sorting the dataframe by the new ID column\n",
    "    df_sorted = df.sort_values(by='participant_ID')\n",
    "    return df_sorted\n",
    "\n",
    "# Applying the function to each dataframe\n",
    "lexical_decision_part1_sorted = process_dataframe(lexical_decision_part1)\n",
    "lexical_decision_part2_sorted = process_dataframe(lexical_decision_part2)\n",
    "recognition_memory_part1_sorted = process_dataframe(recognition_memory_part1)\n",
    "recognition_memory_part2_sorted = process_dataframe(recognition_memory_part2)\n",
    "\n",
    "# Saving the sorted dataframes to new CSV files\n",
    "file_ld_part1_sorted = 'lexical_decision_part1_sorted.csv'\n",
    "file_ld_part2_sorted = 'lexical_decision_part2_sorted.csv'\n",
    "file_rm_part1_sorted = 'recognition_memory_part1_sorted.csv'\n",
    "file_rm_part2_sorted = 'recognition_memory_part2_sorted.csv'\n",
    "\n",
    "lexical_decision_part1_sorted.to_csv(file_ld_part1_sorted, index=False)\n",
    "lexical_decision_part2_sorted.to_csv(file_ld_part2_sorted, index=False)\n",
    "recognition_memory_part1_sorted.to_csv(file_rm_part1_sorted, index=False)\n",
    "recognition_memory_part2_sorted.to_csv(file_rm_part2_sorted, index=False)\n",
    "\n",
    "file_ld_part1_sorted, file_ld_part2_sorted, file_rm_part1_sorted, file_rm_part2_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b76c879d-3eaf-4d6a-b267-bd0ff9144e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>v1_mean</th>\n",
       "      <th>v2_mean</th>\n",
       "      <th>a_mean</th>\n",
       "      <th>ndt_mean</th>\n",
       "      <th>alpha_mean</th>\n",
       "      <th>accuracy_percentage</th>\n",
       "      <th>mean_log_rt</th>\n",
       "      <th>RT_mean_correct_error</th>\n",
       "      <th>mean_correct</th>\n",
       "      <th>...</th>\n",
       "      <th>q1_E</th>\n",
       "      <th>q2_E</th>\n",
       "      <th>q3_E</th>\n",
       "      <th>q4_E</th>\n",
       "      <th>participant_ID</th>\n",
       "      <th>alpha_mean_shifted</th>\n",
       "      <th>alpha_mean_arcsin</th>\n",
       "      <th>alpha_mean_boxcox_after_arcsin</th>\n",
       "      <th>accuracy_percentage_arcsin</th>\n",
       "      <th>accuracy_percentage_boxcox_after_arcsin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>001_class_words_part_1.dat</td>\n",
       "      <td>1.744349</td>\n",
       "      <td>-1.632886</td>\n",
       "      <td>1.175685</td>\n",
       "      <td>0.374896</td>\n",
       "      <td>1.381957</td>\n",
       "      <td>0.899749</td>\n",
       "      <td>6.522493</td>\n",
       "      <td>0.701662</td>\n",
       "      <td>0.703426</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.41  0.467 0.491 0.41  0.523 0.521 0.409 0.5...</td>\n",
       "      <td>[0.626 0.617 0.602 0.547 0.562 0.539 0.538 0.5...</td>\n",
       "      <td>[0.755 0.667 0.858 0.642 0.641 0.682 0.818 0.7...</td>\n",
       "      <td>[0.89  0.954 0.914 0.914 1.017 0.875 1.235 0.8...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.381957</td>\n",
       "      <td>0.666231</td>\n",
       "      <td>-0.262745</td>\n",
       "      <td>1.248628</td>\n",
       "      <td>0.478991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>002_class_words_part_1.dat</td>\n",
       "      <td>2.162214</td>\n",
       "      <td>-1.557720</td>\n",
       "      <td>1.174118</td>\n",
       "      <td>0.528709</td>\n",
       "      <td>1.897042</td>\n",
       "      <td>0.914573</td>\n",
       "      <td>6.651658</td>\n",
       "      <td>0.809281</td>\n",
       "      <td>0.795657</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.762 0.619 0.682 0.594 0.77  0.634 0.738 0.5...</td>\n",
       "      <td>[0.794 0.803 0.794 0.842 0.834 0.802 0.858 0.834]</td>\n",
       "      <td>[0.995 0.946 0.866 0.946 0.939 0.906 0.995 0.874]</td>\n",
       "      <td>[1.035 1.281 1.027 1.122 2.306 1.026 1.018 1.1...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.897042</td>\n",
       "      <td>1.244148</td>\n",
       "      <td>0.284687</td>\n",
       "      <td>1.274187</td>\n",
       "      <td>0.564924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>003_class_words_part_1.dat</td>\n",
       "      <td>3.005359</td>\n",
       "      <td>-2.639568</td>\n",
       "      <td>1.275063</td>\n",
       "      <td>0.452021</td>\n",
       "      <td>1.912452</td>\n",
       "      <td>0.977500</td>\n",
       "      <td>6.492267</td>\n",
       "      <td>0.680427</td>\n",
       "      <td>0.675969</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.555 0.586 0.538]</td>\n",
       "      <td>[0.594 0.593]</td>\n",
       "      <td>[0.795 0.833]</td>\n",
       "      <td>[1.347 2.026]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.912452</td>\n",
       "      <td>1.270414</td>\n",
       "      <td>0.320273</td>\n",
       "      <td>1.420228</td>\n",
       "      <td>1.264399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>004_class_words_part_1.dat</td>\n",
       "      <td>2.446619</td>\n",
       "      <td>-2.340666</td>\n",
       "      <td>1.128517</td>\n",
       "      <td>0.397490</td>\n",
       "      <td>1.468022</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>6.427847</td>\n",
       "      <td>0.631073</td>\n",
       "      <td>0.631511</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.45  0.482 0.514 0.475 0.386 0.498 0.418]</td>\n",
       "      <td>[0.522 0.523 0.53  0.522 0.578 0.522 0.578 0.529]</td>\n",
       "      <td>[0.609 0.675 0.666 0.634 0.658 0.579]</td>\n",
       "      <td>[0.795 0.682 0.866 1.138 0.914 0.794 0.97 ]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.468022</td>\n",
       "      <td>0.753399</td>\n",
       "      <td>-0.207404</td>\n",
       "      <td>1.303033</td>\n",
       "      <td>0.673343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>005_class_words_part_1.dat</td>\n",
       "      <td>3.876715</td>\n",
       "      <td>-3.086337</td>\n",
       "      <td>1.512660</td>\n",
       "      <td>0.415362</td>\n",
       "      <td>1.874313</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>6.439964</td>\n",
       "      <td>0.642445</td>\n",
       "      <td>0.639586</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.611 0.61 ]</td>\n",
       "      <td>[0.642]</td>\n",
       "      <td>[0.947]</td>\n",
       "      <td>[1.073 1.098]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.874313</td>\n",
       "      <td>1.208392</td>\n",
       "      <td>0.237823</td>\n",
       "      <td>1.448014</td>\n",
       "      <td>1.446927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Experiment   v1_mean   v2_mean    a_mean  ndt_mean  \\\n",
       "368  001_class_words_part_1.dat  1.744349 -1.632886  1.175685  0.374896   \n",
       "108  002_class_words_part_1.dat  2.162214 -1.557720  1.174118  0.528709   \n",
       "347  003_class_words_part_1.dat  3.005359 -2.639568  1.275063  0.452021   \n",
       "97   004_class_words_part_1.dat  2.446619 -2.340666  1.128517  0.397490   \n",
       "62   005_class_words_part_1.dat  3.876715 -3.086337  1.512660  0.415362   \n",
       "\n",
       "     alpha_mean  accuracy_percentage  mean_log_rt  RT_mean_correct_error  \\\n",
       "368    1.381957             0.899749     6.522493               0.701662   \n",
       "108    1.897042             0.914573     6.651658               0.809281   \n",
       "347    1.912452             0.977500     6.492267               0.680427   \n",
       "97     1.468022             0.930000     6.427847               0.631073   \n",
       "62     1.874313             0.985000     6.439964               0.642445   \n",
       "\n",
       "     mean_correct  ...                                               q1_E  \\\n",
       "368      0.703426  ...  [0.41  0.467 0.491 0.41  0.523 0.521 0.409 0.5...   \n",
       "108      0.795657  ...  [0.762 0.619 0.682 0.594 0.77  0.634 0.738 0.5...   \n",
       "347      0.675969  ...                                [0.555 0.586 0.538]   \n",
       "97       0.631511  ...        [0.45  0.482 0.514 0.475 0.386 0.498 0.418]   \n",
       "62       0.639586  ...                                      [0.611 0.61 ]   \n",
       "\n",
       "                                                  q2_E  \\\n",
       "368  [0.626 0.617 0.602 0.547 0.562 0.539 0.538 0.5...   \n",
       "108  [0.794 0.803 0.794 0.842 0.834 0.802 0.858 0.834]   \n",
       "347                                      [0.594 0.593]   \n",
       "97   [0.522 0.523 0.53  0.522 0.578 0.522 0.578 0.529]   \n",
       "62                                             [0.642]   \n",
       "\n",
       "                                                  q3_E  \\\n",
       "368  [0.755 0.667 0.858 0.642 0.641 0.682 0.818 0.7...   \n",
       "108  [0.995 0.946 0.866 0.946 0.939 0.906 0.995 0.874]   \n",
       "347                                      [0.795 0.833]   \n",
       "97               [0.609 0.675 0.666 0.634 0.658 0.579]   \n",
       "62                                             [0.947]   \n",
       "\n",
       "                                                  q4_E participant_ID  \\\n",
       "368  [0.89  0.954 0.914 0.914 1.017 0.875 1.235 0.8...              1   \n",
       "108  [1.035 1.281 1.027 1.122 2.306 1.026 1.018 1.1...              2   \n",
       "347                                      [1.347 2.026]              3   \n",
       "97         [0.795 0.682 0.866 1.138 0.914 0.794 0.97 ]              4   \n",
       "62                                       [1.073 1.098]              5   \n",
       "\n",
       "    alpha_mean_shifted alpha_mean_arcsin alpha_mean_boxcox_after_arcsin  \\\n",
       "368           0.381957          0.666231                      -0.262745   \n",
       "108           0.897042          1.244148                       0.284687   \n",
       "347           0.912452          1.270414                       0.320273   \n",
       "97            0.468022          0.753399                      -0.207404   \n",
       "62            0.874313          1.208392                       0.237823   \n",
       "\n",
       "    accuracy_percentage_arcsin accuracy_percentage_boxcox_after_arcsin  \n",
       "368                   1.248628                                0.478991  \n",
       "108                   1.274187                                0.564924  \n",
       "347                   1.420228                                1.264399  \n",
       "97                    1.303033                                0.673343  \n",
       "62                    1.448014                                1.446927  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Function to apply the transformations\n",
    "def apply_transformations(df):\n",
    "    # Transformation for alpha\n",
    "    df['alpha_mean_shifted'] = df['alpha_mean'] - 1\n",
    "    df['alpha_mean_arcsin'] = np.arcsin(np.sqrt(df['alpha_mean_shifted'].clip(0)))\n",
    "    df['alpha_mean_boxcox_after_arcsin'], _ = stats.boxcox(df['alpha_mean_arcsin'] + 1e-9) # Adding a small constant to avoid zero values\n",
    "\n",
    "    # Transformation for accuracy_percentage\n",
    "    df['accuracy_percentage_arcsin'] = np.arcsin(np.sqrt(df['accuracy_percentage']))\n",
    "    df['accuracy_percentage_boxcox_after_arcsin'], _ = stats.boxcox(df['accuracy_percentage_arcsin'] + 1e-9) # Adding a small constant to avoid zero values\n",
    "\n",
    "    return df\n",
    "\n",
    "# Applying the transformations to each dataframe\n",
    "lexical_decision_part1_transformed = apply_transformations(lexical_decision_part1_sorted)\n",
    "lexical_decision_part2_transformed = apply_transformations(lexical_decision_part2_sorted)\n",
    "recognition_memory_part1_transformed = apply_transformations(recognition_memory_part1_sorted)\n",
    "recognition_memory_part2_transformed = apply_transformations(recognition_memory_part2_sorted)\n",
    "\n",
    "# Preview one of the transformed dataframes\n",
    "lexical_decision_part1_transformed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f8fc977-f05f-4cdb-b22d-e749d0cf3f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('EZ_lexical_decision_part1_transformed.csv',\n",
       " 'EZ_lexical_decision_part2_transformed.csv',\n",
       " 'EZ_recognition_memory_part1_transformed.csv',\n",
       " 'EZ_recognition_memory_part2_transformed.csv')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the transformed dataframes to new CSV files\n",
    "file_ld_part1_transformed = 'EZ_lexical_decision_part1_transformed.csv'\n",
    "file_ld_part2_transformed = 'EZ_lexical_decision_part2_transformed.csv'\n",
    "file_rm_part1_transformed = 'EZ_recognition_memory_part1_transformed.csv'\n",
    "file_rm_part2_transformed = 'EZ_recognition_memory_part2_transformed.csv'\n",
    "\n",
    "lexical_decision_part1_transformed.to_csv(file_ld_part1_transformed, index=False)\n",
    "lexical_decision_part2_transformed.to_csv(file_ld_part2_transformed, index=False)\n",
    "recognition_memory_part1_transformed.to_csv(file_rm_part1_transformed, index=False)\n",
    "recognition_memory_part2_transformed.to_csv(file_rm_part2_transformed, index=False)\n",
    "\n",
    "file_ld_part1_transformed, file_ld_part2_transformed, file_rm_part1_transformed, file_rm_part2_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0d0d5-a898-4d10-9357-6c16449d1bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
